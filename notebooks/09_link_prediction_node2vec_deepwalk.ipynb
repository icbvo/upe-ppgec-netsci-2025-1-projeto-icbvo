{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0b9c095c",
   "metadata": {},
   "source": [
    "# 09 - Link Prediction com Embeddings Node2Vec e DeepWalk\n",
    "\n",
    "Este notebook utiliza os embeddings gerados por **Node2Vec** e **DeepWalk** para a tarefa de **predi√ß√£o de arestas**, usando o mesmo split de arestas criado no Notebook 08.\n",
    "\n",
    "Fluxo:\n",
    "\n",
    "1. Carregar os splits de arestas (`08_edge_splits.csv`).\n",
    "2. Carregar embeddings `node2vec_embeddings.csv` e `deepwalk_embeddings.csv`.\n",
    "3. Construir features para arestas a partir dos embeddings (Hadamard + |diferen√ßa|).\n",
    "4. Treinar regress√£o log√≠stica para prever links.\n",
    "5. Avaliar em train/val/test (AUC, AP) e salvar os resultados em CSV.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0374b5d1-2cb3-427a-8cc4-06707781fc4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: node2vec in /usr/local/lib/python3.11/site-packages (0.5.0)\n",
      "Requirement already satisfied: gensim<5.0.0,>=4.3.0 in /usr/local/lib/python3.11/site-packages (from node2vec) (4.4.0)\n",
      "Requirement already satisfied: joblib<2.0.0,>=1.4.0 in /usr/local/lib/python3.11/site-packages (from node2vec) (1.5.3)\n",
      "Requirement already satisfied: networkx<4.0.0,>=3.1.0 in /usr/local/lib/python3.11/site-packages (from node2vec) (3.2.1)\n",
      "Requirement already satisfied: numpy<2.0.0,>=1.24.0 in /usr/local/lib/python3.11/site-packages (from node2vec) (1.26.4)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.66.1 in /usr/local/lib/python3.11/site-packages (from node2vec) (4.66.2)\n",
      "Requirement already satisfied: scipy>=1.7.0 in /usr/local/lib/python3.11/site-packages (from gensim<5.0.0,>=4.3.0->node2vec) (1.16.3)\n",
      "Requirement already satisfied: smart_open>=1.8.1 in /usr/local/lib/python3.11/site-packages (from gensim<5.0.0,>=4.3.0->node2vec) (7.5.0)\n",
      "Requirement already satisfied: wrapt in /usr/local/lib/python3.11/site-packages (from smart_open>=1.8.1->gensim<5.0.0,>=4.3.0->node2vec) (2.0.1)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install node2vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "45802364-484c-41da-92fc-91ee277e9c5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running Node2Vec + DeepWalk generator from Jupyter notebook...\n",
      "EDGELIST_PATH: /workspace/data/collaboration.edgelist.txt exists= True\n",
      "Saving results in: /workspace/results\n",
      "   source  target\n",
      "0       0    1680\n",
      "1       0    6918\n",
      "2       0   19642\n",
      "3       1    4131\n",
      "4       1    5645\n",
      "\n",
      "=== GRAPH OVERVIEW ===\n",
      "nodes: 23133\n",
      "edges: 93439\n",
      "\n",
      "==================== TRAINING NODE2VEC =======================\n",
      "Computing transition probabilities: 100%|‚ñà| 23133/23133 [00:05<00:00, 4304.25it/\n",
      "Generating walks (CPU: 1): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 5/5 [00:06<00:00,  1.21s/it]\n",
      "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
      "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
      "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
      "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
      "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
      "Saved: /workspace/results/node2vec_embeddings.csv\n",
      "\n",
      "==================== TRAINING DEEPWALK =======================\n",
      "Computing transition probabilities: 100%|‚ñà| 23133/23133 [00:05<00:00, 4206.55it/\n",
      "Generating walks (CPU: 1): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3/3 [00:02<00:00,  1.41it/s]\n",
      "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
      "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
      "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
      "Saved: /workspace/results/deepwalk_embeddings.csv\n",
      "\n",
      "Done! üöÄ\n",
      "\n",
      "Verifying files:\n",
      "\n",
      "-rw-r--r-- 1 root root  13M Dec 16 23:22 06_embeddings_with_degree.csv\n",
      "-rw-r--r-- 1 root root  13M Dec 16 23:22 06_node_embeddings_raw.csv\n",
      "-rw-r--r-- 1 root root  13M Dec 16 23:22 06_node_embeddings_with_pca.csv\n",
      "-rw-r--r-- 1 root root  14M Dec 16 23:23 07_embeddings_lcc_communities.csv\n",
      "-rw-r--r-- 1 root root  14M Dec 16 23:23 07_embeddings_with_graph_features.csv\n",
      "-rw-r--r-- 1 root root 8.1M Dec 16 23:26 deepwalk_embeddings.csv\n",
      "-rw-r--r-- 1 root root  16M Dec 16 23:26 node2vec_embeddings.csv\n",
      "-rw-r--r-- 1 root root 5.7M Dec 10 19:09 node_embeddings.pt\n"
     ]
    }
   ],
   "source": [
    "print(\"Running Node2Vec + DeepWalk generator from Jupyter notebook...\")\n",
    "!python ../analysis/node2vec_deepwalk.py\n",
    "\n",
    "print(\"\\nVerifying files:\\n\")\n",
    "!ls -lh /workspace/results | grep embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1ef5e58e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTEBOOK_DIR: /workspaces/upe-ppgec-netsci-2025-1-projeto-icbvo/notebooks\n",
      "PROJECT_DIR : /workspaces/upe-ppgec-netsci-2025-1-projeto-icbvo\n",
      "DATA_DIR    : /workspaces/upe-ppgec-netsci-2025-1-projeto-icbvo/data\n",
      "RESULTS_DIR : /workspaces/upe-ppgec-netsci-2025-1-projeto-icbvo/results\n",
      "NODE2VEC   : /workspaces/upe-ppgec-netsci-2025-1-projeto-icbvo/results/node2vec_embeddings.csv | exists = True\n",
      "DEEPWALK   : /workspaces/upe-ppgec-netsci-2025-1-projeto-icbvo/results/deepwalk_embeddings.csv | exists = True\n",
      "SPLITS     : /workspaces/upe-ppgec-netsci-2025-1-projeto-icbvo/results/08_edge_splits.csv | exists = True\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import roc_auc_score, average_precision_score\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.style.use(\"default\")\n",
    "\n",
    "# === Detectar automaticamente o diret√≥rio raiz do projeto ===\n",
    "NOTEBOOK_DIR = Path.cwd()                      # /workspaces/.../notebooks\n",
    "PROJECT_DIR = NOTEBOOK_DIR.parent              # /workspaces/.../\n",
    "DATA_DIR = PROJECT_DIR / \"data\"\n",
    "RESULTS_DIR = PROJECT_DIR / \"results\"\n",
    "FIG_DIR = RESULTS_DIR / \"figures\"\n",
    "\n",
    "RESULTS_DIR.mkdir(exist_ok=True, parents=True)\n",
    "FIG_DIR.mkdir(exist_ok=True, parents=True)\n",
    "\n",
    "# === Caminhos dos arquivos produzidos anteriormente ===\n",
    "SPLITS_PATH    = RESULTS_DIR / \"08_edge_splits.csv\"\n",
    "NODE2VEC_CSV   = RESULTS_DIR / \"node2vec_embeddings.csv\"\n",
    "DEEPWALK_CSV   = RESULTS_DIR / \"deepwalk_embeddings.csv\"\n",
    "\n",
    "print(\"NOTEBOOK_DIR:\", NOTEBOOK_DIR)\n",
    "print(\"PROJECT_DIR :\", PROJECT_DIR)\n",
    "print(\"DATA_DIR    :\", DATA_DIR)\n",
    "print(\"RESULTS_DIR :\", RESULTS_DIR)\n",
    "print(\"NODE2VEC   :\", NODE2VEC_CSV, \"| exists =\", NODE2VEC_CSV.exists())\n",
    "print(\"DEEPWALK   :\", DEEPWALK_CSV, \"| exists =\", DEEPWALK_CSV.exists())\n",
    "print(\"SPLITS     :\", SPLITS_PATH, \"| exists =\", SPLITS_PATH.exists())\n",
    "\n",
    "if not SPLITS_PATH.exists():\n",
    "    raise FileNotFoundError(\"Arquivo 08_edge_splits.csv n√£o encontrado ‚Äî execute o Notebook 08 primeiro.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f9b6bfc",
   "metadata": {},
   "source": [
    "## 1. Carregar splits de arestas (os mesmos do Notebook 08)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "84cf0575",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       u      v  label  split\n",
      "0  14097  19856      1  train\n",
      "1  16449  10738      1  train\n",
      "2  10217  12337      1  train\n",
      "3   8516  12628      1  train\n",
      "4  10310  18193      1  train\n",
      "Splits:\n",
      "split\n",
      "train    130814\n",
      "test      28034\n",
      "val       28030\n",
      "Name: count, dtype: int64\n",
      "Labels:\n",
      "label\n",
      "1    93439\n",
      "0    93439\n",
      "Name: count, dtype: int64\n",
      "Train shape: (130814, 4)\n",
      "Val shape: (28030, 4)\n",
      "Test shape: (28034, 4)\n"
     ]
    }
   ],
   "source": [
    "df_edges_all = pd.read_csv(SPLITS_PATH)\n",
    "print(df_edges_all.head())\n",
    "print(\"Splits:\")\n",
    "print(df_edges_all[\"split\"].value_counts())\n",
    "print(\"Labels:\")\n",
    "print(df_edges_all[\"label\"].value_counts())\n",
    "\n",
    "df_train = df_edges_all[df_edges_all[\"split\"] == \"train\"].reset_index(drop=True)\n",
    "df_val = df_edges_all[df_edges_all[\"split\"] == \"val\"].reset_index(drop=True)\n",
    "df_test = df_edges_all[df_edges_all[\"split\"] == \"test\"].reset_index(drop=True)\n",
    "\n",
    "print(\"Train shape:\", df_train.shape)\n",
    "print(\"Val shape:\", df_val.shape)\n",
    "print(\"Test shape:\", df_test.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d78de846",
   "metadata": {},
   "source": [
    "## 2. Fun√ß√µes gen√©ricas para carregar embeddings e montar features de arestas\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "31bd6115",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_embeddings(path: Path) -> pd.DataFrame:\n",
    "    print(\"Loading:\", path)\n",
    "    \n",
    "    if not path.exists():\n",
    "        raise FileNotFoundError(f\"Arquivo n√£o encontrado: {path}\")\n",
    "\n",
    "    df = pd.read_csv(path)\n",
    "\n",
    "    # Tenta detectar automaticamente a coluna 'node'\n",
    "    possible_cols = [\"node\", \"id\", \"vertex\", \"index\"]\n",
    "    found = None\n",
    "    for c in possible_cols:\n",
    "        if c in df.columns:\n",
    "            found = c\n",
    "            break\n",
    "\n",
    "    if found is None:\n",
    "        raise ValueError(f\"Nenhuma coluna de id encontrada em {path}. \"\n",
    "                         f\"Esperado uma dessas: {possible_cols}\")\n",
    "\n",
    "    df = df.rename(columns={found: \"node\"})\n",
    "    df[\"node\"] = df[\"node\"].astype(int)\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "\n",
    "def build_emb_dict(df_emb: pd.DataFrame) -> dict:\n",
    "    embed_cols = [c for c in df_emb.columns if c.startswith(\"dim_\")]\n",
    "    emb_dim = len(embed_cols)\n",
    "    print(\"Embedding dimension:\", emb_dim)\n",
    "    emb_dict = {\n",
    "        int(row[\"node\"]): row[embed_cols].to_numpy(dtype=float)\n",
    "        for _, row in df_emb.iterrows()\n",
    "    }\n",
    "    return emb_dict, emb_dim\n",
    "\n",
    "\n",
    "def edge_to_features(u: int, v: int, emb_dict: dict, emb_dim: int) -> np.ndarray:\n",
    "    if u not in emb_dict or v not in emb_dict:\n",
    "        raise KeyError(f\"Node {u} or {v} not found in embeddings.\")\n",
    "    z_u = emb_dict[u]\n",
    "    z_v = emb_dict[v]\n",
    "    had = z_u * z_v\n",
    "    diff = np.abs(z_u - z_v)\n",
    "    return np.concatenate([had, diff], axis=0)\n",
    "\n",
    "\n",
    "def build_Xy(df_edges: pd.DataFrame, emb_dict: dict, emb_dim: int):\n",
    "    feat_dim = emb_dim * 2\n",
    "    X = np.zeros((len(df_edges), feat_dim), dtype=float)\n",
    "    y = df_edges[\"label\"].to_numpy(dtype=int)\n",
    "    for i, row in df_edges.iterrows():\n",
    "        X[i] = edge_to_features(int(row[\"u\"]), int(row[\"v\"]), emb_dict, emb_dim)\n",
    "    return X, y\n",
    "\n",
    "\n",
    "def evaluate_link_prediction(emb_name: str, df_train, df_val, df_test, emb_dict: dict, emb_dim: int):\n",
    "    from sklearn.linear_model import LogisticRegression\n",
    "    from sklearn.metrics import roc_auc_score, average_precision_score\n",
    "\n",
    "    print(f\"\\n=== Avaliando embeddings: {emb_name} ===\")\n",
    "\n",
    "    X_train, y_train = build_Xy(df_train, emb_dict, emb_dim)\n",
    "    X_val, y_val = build_Xy(df_val, emb_dict, emb_dim)\n",
    "    X_test, y_test = build_Xy(df_test, emb_dict, emb_dim)\n",
    "\n",
    "    print(\"X_train shape:\", X_train.shape, \"y_train shape:\", y_train.shape)\n",
    "\n",
    "    clf = LogisticRegression(max_iter=1000, class_weight=\"balanced\", n_jobs=-1)\n",
    "    clf.fit(X_train, y_train)\n",
    "\n",
    "    def eval_split(name, X, y):\n",
    "        y_scores = clf.predict_proba(X)[:, 1]\n",
    "        auc = roc_auc_score(y, y_scores)\n",
    "        ap = average_precision_score(y, y_scores)\n",
    "        print(f\"{emb_name} | {name} - AUC: {auc:.4f}, AP: {ap:.4f}\")\n",
    "        return {\n",
    "            \"embedding\": emb_name,\n",
    "            \"split\": name,\n",
    "            \"auc\": auc,\n",
    "            \"ap\": ap,\n",
    "            \"num_samples\": len(y),\n",
    "            \"pos_samples\": int(y.sum()),\n",
    "            \"neg_samples\": int((y == 0).sum()),\n",
    "        }\n",
    "\n",
    "    results = []\n",
    "    results.append(eval_split(\"train\", X_train, y_train))\n",
    "    results.append(eval_split(\"val\", X_val, y_val))\n",
    "    results.append(eval_split(\"test\", X_test, y_test))\n",
    "\n",
    "    return pd.DataFrame(results)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1342388d",
   "metadata": {},
   "source": [
    "## 3. Avaliar Node2Vec\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8d6f820d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading: /workspaces/upe-ppgec-netsci-2025-1-projeto-icbvo/results/node2vec_embeddings.csv\n",
      "Node2Vec embeddings shape: (23133, 65)\n",
      "Embedding dimension: 64\n",
      "\n",
      "=== Avaliando embeddings: node2vec ===\n",
      "X_train shape: (130814, 128) y_train shape: (130814,)\n",
      "node2vec | train - AUC: 0.9994, AP: 0.9992\n",
      "node2vec | val - AUC: 0.9996, AP: 0.9996\n",
      "node2vec | test - AUC: 0.9995, AP: 0.9995\n",
      "Saved Node2Vec link prediction results to: /workspaces/upe-ppgec-netsci-2025-1-projeto-icbvo/results/09_node2vec_link_prediction_results.csv\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>embedding</th>\n",
       "      <th>split</th>\n",
       "      <th>auc</th>\n",
       "      <th>ap</th>\n",
       "      <th>num_samples</th>\n",
       "      <th>pos_samples</th>\n",
       "      <th>neg_samples</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>node2vec</td>\n",
       "      <td>train</td>\n",
       "      <td>0.999385</td>\n",
       "      <td>0.999237</td>\n",
       "      <td>130814</td>\n",
       "      <td>65407</td>\n",
       "      <td>65407</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>node2vec</td>\n",
       "      <td>val</td>\n",
       "      <td>0.999580</td>\n",
       "      <td>0.999562</td>\n",
       "      <td>28030</td>\n",
       "      <td>14015</td>\n",
       "      <td>14015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>node2vec</td>\n",
       "      <td>test</td>\n",
       "      <td>0.999527</td>\n",
       "      <td>0.999473</td>\n",
       "      <td>28034</td>\n",
       "      <td>14017</td>\n",
       "      <td>14017</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  embedding  split       auc        ap  num_samples  pos_samples  neg_samples\n",
       "0  node2vec  train  0.999385  0.999237       130814        65407        65407\n",
       "1  node2vec    val  0.999580  0.999562        28030        14015        14015\n",
       "2  node2vec   test  0.999527  0.999473        28034        14017        14017"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_node2vec = load_embeddings(NODE2VEC_CSV)\n",
    "print(\"Node2Vec embeddings shape:\", df_node2vec.shape)\n",
    "emb_dict_n2v, emb_dim_n2v = build_emb_dict(df_node2vec)\n",
    "\n",
    "df_results_node2vec = evaluate_link_prediction(\n",
    "    emb_name=\"node2vec\",\n",
    "    df_train=df_train,\n",
    "    df_val=df_val,\n",
    "    df_test=df_test,\n",
    "    emb_dict=emb_dict_n2v,\n",
    "    emb_dim=emb_dim_n2v,\n",
    ")\n",
    "\n",
    "n2v_results_path = RESULTS_DIR / \"09_node2vec_link_prediction_results.csv\"\n",
    "df_results_node2vec.to_csv(n2v_results_path, index=False)\n",
    "print(\"Saved Node2Vec link prediction results to:\", n2v_results_path)\n",
    "\n",
    "display(df_results_node2vec)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f7ab775",
   "metadata": {},
   "source": [
    "## 4. Avaliar DeepWalk (Node2Vec com p = q = 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a098806c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading: /workspaces/upe-ppgec-netsci-2025-1-projeto-icbvo/results/deepwalk_embeddings.csv\n",
      "DeepWalk embeddings shape: (23133, 33)\n",
      "Embedding dimension: 32\n",
      "\n",
      "=== Avaliando embeddings: deepwalk ===\n",
      "X_train shape: (130814, 64) y_train shape: (130814,)\n",
      "deepwalk | train - AUC: 0.9971, AP: 0.9971\n",
      "deepwalk | val - AUC: 0.9973, AP: 0.9975\n",
      "deepwalk | test - AUC: 0.9977, AP: 0.9978\n",
      "Saved DeepWalk link prediction results to: /workspaces/upe-ppgec-netsci-2025-1-projeto-icbvo/results/09_deepwalk_link_prediction_results.csv\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>embedding</th>\n",
       "      <th>split</th>\n",
       "      <th>auc</th>\n",
       "      <th>ap</th>\n",
       "      <th>num_samples</th>\n",
       "      <th>pos_samples</th>\n",
       "      <th>neg_samples</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>deepwalk</td>\n",
       "      <td>train</td>\n",
       "      <td>0.997065</td>\n",
       "      <td>0.997082</td>\n",
       "      <td>130814</td>\n",
       "      <td>65407</td>\n",
       "      <td>65407</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>deepwalk</td>\n",
       "      <td>val</td>\n",
       "      <td>0.997323</td>\n",
       "      <td>0.997500</td>\n",
       "      <td>28030</td>\n",
       "      <td>14015</td>\n",
       "      <td>14015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>deepwalk</td>\n",
       "      <td>test</td>\n",
       "      <td>0.997668</td>\n",
       "      <td>0.997758</td>\n",
       "      <td>28034</td>\n",
       "      <td>14017</td>\n",
       "      <td>14017</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  embedding  split       auc        ap  num_samples  pos_samples  neg_samples\n",
       "0  deepwalk  train  0.997065  0.997082       130814        65407        65407\n",
       "1  deepwalk    val  0.997323  0.997500        28030        14015        14015\n",
       "2  deepwalk   test  0.997668  0.997758        28034        14017        14017"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_deepwalk = load_embeddings(DEEPWALK_CSV)\n",
    "print(\"DeepWalk embeddings shape:\", df_deepwalk.shape)\n",
    "emb_dict_dw, emb_dim_dw = build_emb_dict(df_deepwalk)\n",
    "\n",
    "df_results_deepwalk = evaluate_link_prediction(\n",
    "    emb_name=\"deepwalk\",\n",
    "    df_train=df_train,\n",
    "    df_val=df_val,\n",
    "    df_test=df_test,\n",
    "    emb_dict=emb_dict_dw,\n",
    "    emb_dim=emb_dim_dw,\n",
    ")\n",
    "\n",
    "dw_results_path = RESULTS_DIR / \"09_deepwalk_link_prediction_results.csv\"\n",
    "df_results_deepwalk.to_csv(dw_results_path, index=False)\n",
    "print(\"Saved DeepWalk link prediction results to:\", dw_results_path)\n",
    "\n",
    "display(df_results_deepwalk)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7807ea3f",
   "metadata": {},
   "source": [
    "## 5. Comparar com resultados anteriores (GNN + heur√≠sticas)\n",
    "\n",
    "Nesta c√©lula, vamos carregar:\n",
    "\n",
    "- `08_link_prediction_results.csv` (GNN + embeddings GNN + logistic regression);\n",
    "- `baseline_heuristics_results.csv` (CN, Jaccard, AA, etc.);\n",
    "- e combinar com os resultados de Node2Vec / DeepWalk.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d143e8dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚ö† baseline_heuristics_results.csv n√£o encontrado. Rode baseline_heuristics.py para incluir heur√≠sticas na compara√ß√£o.\n",
      "Saved combined results to: /workspaces/upe-ppgec-netsci-2025-1-projeto-icbvo/results/09_link_prediction_comparison.csv\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>embedding</th>\n",
       "      <th>split</th>\n",
       "      <th>auc</th>\n",
       "      <th>ap</th>\n",
       "      <th>num_samples</th>\n",
       "      <th>pos_samples</th>\n",
       "      <th>neg_samples</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>node2vec</td>\n",
       "      <td>test</td>\n",
       "      <td>0.999527</td>\n",
       "      <td>0.999473</td>\n",
       "      <td>28034</td>\n",
       "      <td>14017</td>\n",
       "      <td>14017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>deepwalk</td>\n",
       "      <td>test</td>\n",
       "      <td>0.997668</td>\n",
       "      <td>0.997758</td>\n",
       "      <td>28034</td>\n",
       "      <td>14017</td>\n",
       "      <td>14017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>gnn</td>\n",
       "      <td>test</td>\n",
       "      <td>0.919111</td>\n",
       "      <td>0.909965</td>\n",
       "      <td>28034</td>\n",
       "      <td>14017</td>\n",
       "      <td>14017</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  embedding split       auc        ap  num_samples  pos_samples  neg_samples\n",
       "2  node2vec  test  0.999527  0.999473        28034        14017        14017\n",
       "5  deepwalk  test  0.997668  0.997758        28034        14017        14017\n",
       "8       gnn  test  0.919111  0.909965        28034        14017        14017"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "gnn_results_path = RESULTS_DIR / \"08_link_prediction_results.csv\"\n",
    "baseline_results_path = RESULTS_DIR / \"baseline_heuristics_results.csv\"\n",
    "\n",
    "if not gnn_results_path.exists():\n",
    "    print(\"‚ö† 08_link_prediction_results.csv n√£o encontrado. Rode o Notebook 08 para incluir GNN na compara√ß√£o.\")\n",
    "    df_gnn = pd.DataFrame()\n",
    "else:\n",
    "    df_gnn = pd.read_csv(gnn_results_path)\n",
    "    df_gnn[\"embedding\"] = \"gnn\"\n",
    "\n",
    "if not baseline_results_path.exists():\n",
    "    print(\"‚ö† baseline_heuristics_results.csv n√£o encontrado. Rode baseline_heuristics.py para incluir heur√≠sticas na compara√ß√£o.\")\n",
    "    df_baseline = pd.DataFrame()\n",
    "else:\n",
    "    df_baseline = pd.read_csv(baseline_results_path)\n",
    "    # renomear para ficar compat√≠vel: heuristic -> embedding\n",
    "    df_baseline = df_baseline.rename(columns={\"heuristic\": \"embedding\"})\n",
    "\n",
    "df_all_results = []\n",
    "df_all_results.append(df_results_node2vec)\n",
    "df_all_results.append(df_results_deepwalk)\n",
    "if not df_gnn.empty:\n",
    "    df_all_results.append(df_gnn)\n",
    "if not df_baseline.empty:\n",
    "    df_all_results.append(df_baseline)\n",
    "\n",
    "df_all_results = pd.concat(df_all_results, ignore_index=True)\n",
    "\n",
    "comparison_path = RESULTS_DIR / \"09_link_prediction_comparison.csv\"\n",
    "df_all_results.to_csv(comparison_path, index=False)\n",
    "print(\"Saved combined results to:\", comparison_path)\n",
    "\n",
    "display(df_all_results[df_all_results[\"split\"] == \"test\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f8f2c57a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Notebook 09 finished successfully. üöÄ\n"
     ]
    }
   ],
   "source": [
    "print('Notebook 09 finished successfully. üöÄ')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
