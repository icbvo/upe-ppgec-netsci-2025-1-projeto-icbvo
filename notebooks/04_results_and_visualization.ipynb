{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 04 – Results and Visualization\n",
    "\n",
    "This notebook aggregates the main results and visualizations from the project:\n",
    "\n",
    "- Global graph summary (full network)\n",
    "- Network properties of the largest connected component (LCC)\n",
    "- Centrality measures (degree, betweenness, eigenvector)\n",
    "- GNN link prediction performance (test AUC, test AP)\n",
    "- Simple plots and a LaTeX table snippet for the research paper\n",
    "\n",
    "It assumes the following files have been generated by previous scripts / notebooks:\n",
    "\n",
    "- `../results/graph_summary.json` (from `01_exploration.ipynb`)\n",
    "- `../results/network_properties_lcc.json` (from `02_network_properties.ipynb`)\n",
    "- `../results/centrality_lcc.csv` (from `02_network_properties.ipynb`)\n",
    "- `../results/linkpred_metrics.json` (from `train_link_prediction_gnn.py`)\n",
    "\n",
    "This notebook is meant to support the **Results** and **Discussion** sections of the paper."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup and Imports\n",
    "\n",
    "We set the project root as `..` and load all relevant result files from the `../results/` directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "PROJECT_ROOT = Path(\"..\").resolve()\n",
    "RESULTS_DIR = PROJECT_ROOT / \"results\"\n",
    "\n",
    "GRAPH_SUMMARY_PATH = RESULTS_DIR / \"graph_summary.json\"\n",
    "LCC_PROPS_PATH = RESULTS_DIR / \"network_properties_lcc.json\"\n",
    "CENTRALITY_PATH = RESULTS_DIR / \"centrality_lcc.csv\"\n",
    "METRICS_PATH = RESULTS_DIR / \"linkpred_metrics.json\"\n",
    "\n",
    "PROJECT_ROOT, RESULTS_DIR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Load Summary Files\n",
    "\n",
    "We load:\n",
    "\n",
    "- Global graph summary\n",
    "- LCC network properties\n",
    "- Centrality table\n",
    "- GNN link prediction metrics\n",
    "\n",
    "If any file is missing, we print a warning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_json_safe(path: Path):\n",
    "    if path.exists():\n",
    "        with open(path, \"r\") as f:\n",
    "            return json.load(f)\n",
    "    else:\n",
    "        print(f\"[Warning] JSON file not found: {path}\")\n",
    "        return None\n",
    "\n",
    "\n",
    "graph_summary = load_json_safe(GRAPH_SUMMARY_PATH)\n",
    "lcc_props = load_json_safe(LCC_PROPS_PATH)\n",
    "\n",
    "if CENTRALITY_PATH.exists():\n",
    "    centrality_df = pd.read_csv(CENTRALITY_PATH)\n",
    "else:\n",
    "    print(f\"[Warning] Centrality CSV not found: {CENTRALITY_PATH}\")\n",
    "    centrality_df = None\n",
    "\n",
    "metrics = load_json_safe(METRICS_PATH)\n",
    "\n",
    "graph_summary, lcc_props, (centrality_df.head() if centrality_df is not None else None), metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Global Graph Summary (Full Network)\n",
    "\n",
    "We organize the main statistics from `graph_summary.json` in a small table-like view for easier inspection.\n",
    "\n",
    "Typical fields:\n",
    "\n",
    "- `n_nodes`, `n_edges`\n",
    "- `avg_degree`, `median_degree`, `max_degree`\n",
    "- `density`, `average_clustering`, `transitivity`\n",
    "- fraction of nodes in the largest component (if available)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if graph_summary is not None:\n",
    "    graph_summary_df = pd.DataFrame.from_dict(graph_summary, orient=\"index\", columns=[\"value\"])\n",
    "    display(graph_summary_df)\n",
    "else:\n",
    "    print(\"No global graph summary available.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. LCC (Largest Connected Component) Properties\n",
    "\n",
    "We inspect `network_properties_lcc.json`, which typically includes:\n",
    "\n",
    "- `lcc_n_nodes`, `lcc_n_edges`\n",
    "- `lcc_fraction_of_total_nodes`\n",
    "- `average_shortest_path_length`\n",
    "- `diameter_exact_or_none`\n",
    "- `degree_assortativity`\n",
    "\n",
    "These are key values for describing the structure of the collaboration network in the paper."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if lcc_props is not None:\n",
    "    lcc_props_df = pd.DataFrame.from_dict(lcc_props, orient=\"index\", columns=[\"value\"])\n",
    "    display(lcc_props_df)\n",
    "else:\n",
    "    print(\"No LCC properties available.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Centrality Distributions\n",
    "\n",
    "If `centrality_lcc.csv` is available, we:\n",
    "\n",
    "- Show the first few rows\n",
    "- Plot histograms (log scale where appropriate) for:\n",
    "  - Degree centrality\n",
    "  - Betweenness centrality\n",
    "  - Eigenvector centrality (if available)\n",
    "\n",
    "These plots can help identify whether the network has a small core of highly central authors and a long tail of less central authors, which is typical of collaboration networks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if centrality_df is not None:\n",
    "    display(centrality_df.head())\n",
    "\n",
    "    # Avoid issues with zeros and log-scale\n",
    "    eps = 1e-9\n",
    "\n",
    "    plt.figure(figsize=(8, 5))\n",
    "    plt.hist(centrality_df[\"degree_centrality\"], bins=100)\n",
    "    plt.title(\"Degree Centrality Distribution (LCC)\")\n",
    "    plt.xlabel(\"Degree centrality\")\n",
    "    plt.ylabel(\"Frequency\")\n",
    "    plt.yscale(\"log\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    plt.figure(figsize=(8, 5))\n",
    "    plt.hist(centrality_df[\"betweenness_centrality\"] + eps, bins=100)\n",
    "    plt.title(\"Betweenness Centrality Distribution (LCC)\")\n",
    "    plt.xlabel(\"Betweenness centrality\")\n",
    "    plt.ylabel(\"Frequency\")\n",
    "    plt.yscale(\"log\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    if \"eigenvector_centrality\" in centrality_df.columns:\n",
    "        valid_eig = centrality_df[\"eigenvector_centrality\"].dropna()\n",
    "        if len(valid_eig) > 0:\n",
    "            plt.figure(figsize=(8, 5))\n",
    "            plt.hist(valid_eig + eps, bins=100)\n",
    "            plt.title(\"Eigenvector Centrality Distribution (LCC)\")\n",
    "            plt.xlabel(\"Eigenvector centrality\")\n",
    "            plt.ylabel(\"Frequency\")\n",
    "            plt.yscale(\"log\")\n",
    "            plt.tight_layout()\n",
    "            plt.show()\n",
    "else:\n",
    "    print(\"No centrality data available.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also list the **top 10 nodes** according to each centrality measure; this is useful if, later, we want to identify specific authors or patterns in the collaboration structure (even if we do not map node IDs to names in this dataset)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if centrality_df is not None:\n",
    "    def top_k(df, col, k=10):\n",
    "        return df.sort_values(col, ascending=False).head(k)[[\"node\", col]]\n",
    "\n",
    "    print(\"Top 10 nodes by degree centrality:\")\n",
    "    display(top_k(centrality_df, \"degree_centrality\", k=10))\n",
    "\n",
    "    print(\"Top 10 nodes by betweenness centrality:\")\n",
    "    display(top_k(centrality_df, \"betweenness_centrality\", k=10))\n",
    "\n",
    "    if \"eigenvector_centrality\" in centrality_df.columns:\n",
    "        print(\"Top 10 nodes by eigenvector centrality:\")\n",
    "        display(top_k(centrality_df, \"eigenvector_centrality\", k=10))\n",
    "else:\n",
    "    print(\"No centrality data available.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. GNN Link Prediction Metrics\n",
    "\n",
    "We load the final metrics from `linkpred_metrics.json` and show them in a small table.\n",
    "\n",
    "Typically, this includes fields such as:\n",
    "\n",
    "- `test_auc`\n",
    "- `test_ap`\n",
    "- `encoder`\n",
    "- `epochs`\n",
    "\n",
    "These values will be directly used in the *Results* section of the paper."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if metrics is not None:\n",
    "    metrics_df = pd.DataFrame.from_dict(metrics, orient=\"index\", columns=[\"value\"])\n",
    "    display(metrics_df)\n",
    "else:\n",
    "    print(\"No GNN metrics available.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you want, you can format a short textual summary for the paper, such as:\n",
    "\n",
    "> \"Using a GCN-based link prediction model with 64-dimensional node embeddings, we obtained a test AUC of X.XXX and a test Average Precision (AP) of Y.YYY on the collaboration network.\"\n",
    "\n",
    "You can adapt this later depending on the actual values and any baselines you choose to implement (e.g., Common Neighbors, Jaccard, Adamic–Adar, Preferential Attachment)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. LaTeX Table Snippet for the Paper\n",
    "\n",
    "Here we generate a simple LaTeX table snippet based on the available metrics and network properties.\n",
    "\n",
    "You can copy the output and paste it directly into your IEEE/ACM LaTeX document, adjusting labels/captions as needed.\n",
    "\n",
    "The table will summarize:\n",
    "\n",
    "- Number of nodes / edges (full graph)\n",
    "- LCC properties (size, average shortest path length, assortativity)\n",
    "- GNN performance (test AUC, test AP)\n",
    "\n",
    "If some data is missing (e.g., a JSON file was not generated), we fill with `N/A`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_val(d, key, default=\"N/A\"):\n",
    "    if d is None:\n",
    "        return default\n",
    "    return d.get(key, default)\n",
    "\n",
    "n_nodes = get_val(graph_summary, \"n_nodes\")\n",
    "n_edges = get_val(graph_summary, \"n_edges\")\n",
    "avg_degree = get_val(graph_summary, \"avg_degree\")\n",
    "density = get_val(graph_summary, \"density\")\n",
    "\n",
    "lcc_n_nodes = get_val(lcc_props, \"lcc_n_nodes\")\n",
    "lcc_n_edges = get_val(lcc_props, \"lcc_n_edges\")\n",
    "lcc_fraction = get_val(lcc_props, \"lcc_fraction_of_total_nodes\")\n",
    "avg_spl = get_val(lcc_props, \"average_shortest_path_length\")\n",
    "diameter = get_val(lcc_props, \"diameter_exact_or_none\")\n",
    "assortativity = get_val(lcc_props, \"degree_assortativity\")\n",
    "\n",
    "test_auc = get_val(metrics, \"test_auc\")\n",
    "test_ap = get_val(metrics, \"test_ap\")\n",
    "encoder_name = get_val(metrics, \"encoder\")\n",
    "epochs = get_val(metrics, \"epochs\")\n",
    "\n",
    "latex_table = f\"\"\"\\\\begin{{table}}[t]\n",
    "\\\\centering\n",
    "\\\\caption{{Summary of collaboration network and GNN link prediction performance.}}\n",
    "\\\\label{{tab:network-gnn-summary}}\n",
    "\\\\begin{{tabular}}{{ll}}\n",
    "\\\\hline\n",
    "\\\\textbf{{Property}} & \\\\textbf{{Value}} \\\\\\\\ \n",
    "\\\\hline\n",
    "Number of nodes (full graph) & {n_nodes} \\\\\\\\ \n",
    "Number of edges (full graph) & {n_edges} \\\\\\\\ \n",
    "Average degree (full graph) & {avg_degree} \\\\\\\\ \n",
    "Density (full graph) & {density} \\\\\\\\ \n",
    "LCC size (nodes / edges) & {lcc_n_nodes} / {lcc_n_edges} \\\\\\\\ \n",
    "Fraction of nodes in LCC & {lcc_fraction} \\\\\\\\ \n",
    "Average shortest path length (LCC) & {avg_spl} \\\\\\\\ \n",
    "Diameter (LCC) & {diameter} \\\\\\\\ \n",
    "Degree assortativity (LCC) & {assortativity} \\\\\\\\ \n",
    "GNN encoder & {encoder_name} \\\\\\\\ \n",
    "Training epochs & {epochs} \\\\\\\\ \n",
    "Test AUC & {test_auc} \\\\\\\\ \n",
    "Test AP & {test_ap} \\\\\\\\ \n",
    "\\\\hline\n",
    "\\\\end{{tabular}}\n",
    "\\\\end{{table}}\n",
    "\"\"\"\n",
    "\n",
    "print(latex_table)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can now copy the LaTeX snippet above and paste it into your paper. Adjust the caption and label as needed.\n",
    "\n",
    "This completes the **Results and Visualization** stage, linking the numerical analysis, network structure, and GNN performance into a single consistent view suitable for publication."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
