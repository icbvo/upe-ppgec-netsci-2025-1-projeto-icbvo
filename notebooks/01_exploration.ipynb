{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploration Notebook – Collaboration Network\n",
    "\n",
    "This notebook performs an initial exploratory analysis (EDA) of the collaboration network used in the project **“Link Prediction in Collaboration Networks using Graph Neural Networks”**.\n",
    "\n",
    "It corresponds to **Sprint 1: Research Question, Data Collection and Network** in the Network Science course (PPGEC / UPE)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup and Imports\n",
    "\n",
    "We assume the following directory structure:\n",
    "\n",
    "```text\n",
    "upe-ppgec-netsci-2025-1-projeto-icbvo/\n",
    "├── data/\n",
    "│   └── collaboration.edgelist.txt\n",
    "├── gnn/\n",
    "├── notebooks/\n",
    "└── results/\n",
    "```\n",
    "\n",
    "The notebook is inside `notebooks/` and the edge list is located in `../data/collaboration.edgelist.txt`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import networkx as nx\n",
    "from pathlib import Path\n",
    "import json\n",
    "import os\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "DATA_PATH = Path(\"../data/collaboration.edgelist.txt\")\n",
    "RESULTS_DIR = Path(\"../results\")\n",
    "RESULTS_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "DATA_PATH, RESULTS_DIR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Loading the Edge List\n",
    "\n",
    "The file is expected to have **no header** and **two integer columns** (node identifiers), separated by whitespace (space or tab):\n",
    "\n",
    "```text\n",
    "u  v\n",
    "0  1680\n",
    "0  6918\n",
    "...\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not DATA_PATH.exists():\n",
    "    raise FileNotFoundError(f\"Edge list file not found: {DATA_PATH}\")\n",
    "\n",
    "df_edges = pd.read_csv(DATA_PATH, sep=r\"\\s+\", header=None, names=[\"u\", \"v\"])\n",
    "df_edges.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Basic Statistics\n",
    "\n",
    "We compute:\n",
    "\n",
    "- Number of edges\n",
    "- Number of unique nodes\n",
    "- Presence of self-loops\n",
    "- Example of minimum and maximum node IDs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_edges = len(df_edges)\n",
    "nodes = set(df_edges[\"u\"]) | set(df_edges[\"v\"])\n",
    "n_nodes = len(nodes)\n",
    "\n",
    "has_self_loops = (df_edges[\"u\"] == df_edges[\"v\"]).any()\n",
    "min_node = min(nodes)\n",
    "max_node = max(nodes)\n",
    "\n",
    "print(f\"Number of edges: {n_edges}\")\n",
    "print(f\"Number of unique nodes: {n_nodes}\")\n",
    "print(f\"Any self-loops? {has_self_loops}\")\n",
    "print(f\"Min node ID: {min_node}\")\n",
    "print(f\"Max node ID: {max_node}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Building the Graph with NetworkX\n",
    "\n",
    "We treat the network as **undirected**, since collaborations are symmetric (if A collaborated with B, then B collaborated with A)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G = nx.from_pandas_edgelist(df_edges, source=\"u\", target=\"v\")\n",
    "G"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We confirm that the number of nodes and edges in the graph matches the basic statistics computed before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Graph number of nodes: {G.number_of_nodes()}\")\n",
    "print(f\"Graph number of edges: {G.number_of_edges()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Degree Distribution\n",
    "\n",
    "We compute the degree of each node and visualize the distribution.\n",
    "\n",
    "First, we look at the raw histogram; then, we inspect a log–log version to better understand the heavy-tailed behavior."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "degrees = np.array([d for _, d in G.degree()])\n",
    "\n",
    "print(f\"Average degree: {degrees.mean():.2f}\")\n",
    "print(f\"Median degree: {np.median(degrees):.2f}\")\n",
    "print(f\"Max degree: {degrees.max()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 5))\n",
    "plt.hist(degrees, bins=100, color=\"steelblue\")\n",
    "plt.title(\"Degree Distribution (Linear Scale)\")\n",
    "plt.xlabel(\"Degree\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 5))\n",
    "plt.hist(degrees, bins=100, color=\"darkorange\")\n",
    "plt.title(\"Degree Distribution (Log-Log Scale)\")\n",
    "plt.xlabel(\"Degree\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.xscale(\"log\")\n",
    "plt.yscale(\"log\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Connected Components\n",
    "\n",
    "We inspect the number of connected components and the size of the largest connected component (LCC)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_components = nx.number_connected_components(G)\n",
    "lcc_nodes = max(nx.connected_components(G), key=len)\n",
    "lcc_size = len(lcc_nodes)\n",
    "\n",
    "print(f\"Number of connected components: {n_components}\")\n",
    "print(f\"Largest connected component size: {lcc_size}\")\n",
    "print(f\"Fraction of nodes in LCC: {lcc_size / G.number_of_nodes():.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Global Network Properties\n",
    "\n",
    "We compute some basic global measures of the network:\n",
    "\n",
    "- Density\n",
    "- Average clustering coefficient\n",
    "- Transitivity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "density = nx.density(G)\n",
    "avg_clustering = nx.average_clustering(G)\n",
    "transitivity = nx.transitivity(G)\n",
    "\n",
    "print(f\"Density: {density:.6f}\")\n",
    "print(f\"Average clustering coefficient: {avg_clustering:.6f}\")\n",
    "print(f\"Transitivity: {transitivity:.6f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Summary and Export\n",
    "\n",
    "We summarize the main statistics in a Python dictionary and export the results to a JSON file in the `../results/` directory. This can be referenced later in the research paper (Data / Network Description section)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary = {\n",
    "    \"n_nodes\": int(G.number_of_nodes()),\n",
    "    \"n_edges\": int(G.number_of_edges()),\n",
    "    \"has_self_loops\": bool(has_self_loops),\n",
    "    \"min_node_id\": int(min_node),\n",
    "    \"max_node_id\": int(max_node),\n",
    "    \"avg_degree\": float(degrees.mean()),\n",
    "    \"median_degree\": float(np.median(degrees)),\n",
    "    \"max_degree\": int(degrees.max()),\n",
    "    \"n_components\": int(n_components),\n",
    "    \"largest_component_size\": int(lcc_size),\n",
    "    \"largest_component_fraction\": float(lcc_size / G.number_of_nodes()),\n",
    "    \"density\": float(density),\n",
    "    \"average_clustering\": float(avg_clustering),\n",
    "    \"transitivity\": float(transitivity),\n",
    "}\n",
    "\n",
    "summary_path = RESULTS_DIR / \"graph_summary.json\"\n",
    "with open(summary_path, \"w\") as f:\n",
    "    json.dump(summary, f, indent=4)\n",
    "\n",
    "print(f\"Summary saved to: {summary_path}\")\n",
    "summary"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
